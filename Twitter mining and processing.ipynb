{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for mining the twitter feed of a given handle, doing a bit of processing on the gleaned tweets, and saving the data in an csv. It makes use of a seperate python module I wrote to interact with Twitter via tweepy (Tweetmining) and another module I wrote for determining the sentiment of a given word based on how often it is found in pos vs neg tweets (Sentiment_LUT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy #for interacting with Twitter\n",
    "from tweepy import OAuthHandler #for interacting with Twitter\n",
    "import pandas as pd #for saving data\n",
    "import TweetMining #self made module for mining tweets\n",
    "import numpy as np #for maths\n",
    "import Sentiment_LUT #another self made module for creating a sentiment look up table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several def will make this process easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The GloVe table uses information from https://nlp.stanford.edu/projects/glove/ to convert words to numberic 1d vectors.\n",
    "#This def just creates a look up table for taking a word and quickly finding its vector representation.\n",
    "#dimension: can be 25, 50, 200, etc. sets size of word vector representation\n",
    "def GloVe_table(dimension):\n",
    "    file=open('NLP_files/glove.twitter.27B.%sd.txt'%(dimension), 'r',encoding=\"utf8\")\n",
    "    contents=file.read()\n",
    "    contents_lines=contents.split('\\n')\n",
    "    GloVe=pd.DataFrame([line.split(' ') for line in contents_lines[0:]])\n",
    "    GloVe.set_index(0,inplace=True) #set the word as the index for faster look-up table function\n",
    "    return GloVe.iloc[:,:].astype(float).copy()\n",
    "\n",
    "#This uses the Sentiment_LUT module I made previously to judge how often a word shows up in pos tweets vs neg tweets.\n",
    "#If the word shows up more often in one or the other, it will be useful to include in the analysis.\n",
    "#the sentiment_strength variable sets how extreme the imbalance in appearance between pos and neg tweets the word must have\n",
    "#to be used in the analysis.\n",
    "def sent_words(tweet,LUT,sentiment_strength):\n",
    "    tweet_words=pd.Series(tweet.split(' '));\n",
    "    #adding exception in the case there are no sentiment words in tweet.\n",
    "    #In that case, return original tweet.\n",
    "    try:\n",
    "        a=' '.join(tweet_words[(np.abs(LUT.loc[tweet_words,'Score'])>sentiment_strength).values])\n",
    "    except:\n",
    "        a=''\n",
    "    return a\n",
    "\n",
    "#using the GloVe table and sentiment look up table to create vectorized representations of tweets.\n",
    "#names of IMDB and LUT25 are left over from previous work with different training data and GloVe tables.\n",
    "def vectorize(IMDB,dimension,LUT25):\n",
    "    def vector(word):\n",
    "        try:\n",
    "            return LUT25.loc[word,:]\n",
    "        except:\n",
    "            return np.zeros(len(LUT25.iloc[0,:]))\n",
    "    def vector2(word_list):\n",
    "        words=pd.Series(word_list)\n",
    "        a=words.apply(vector).values.mean(axis=0)\n",
    "        return list(a)\n",
    "    for x in range(0,dimension):\n",
    "        IMDB.loc[:,'vector_%s'%(x)]=0\n",
    "    IMDB.loc[:,IMDB.columns[IMDB.columns.str.contains('vector')]]=IMDB.loc[:,'sentiment words'].str.split(' ').apply(vector2).apply(pd.Series).values\n",
    "    return IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a csv file of the twitter handles of every senator currently in the Senate. Instead of manually changing out the handle name each time I want to look at their tweets, I'll write a for loop:\n",
    "\n",
    "Option for doing this with all the senators saved in previous csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senators=pd.read_csv('Senators.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "@SenShelby\n",
      "prev record found\n",
      "1\n",
      "@lutherstrange\n",
      "prev record found\n",
      "2\n",
      "@lisamurkowski\n",
      "prev record found\n",
      "3\n",
      "@SenDanSullivan\n",
      "prev record found\n",
      "4\n",
      "@SenJohnMcCain\n",
      "prev record found\n",
      "5\n",
      "@JeffFlake\n",
      "prev record found\n",
      "6\n",
      "@SenTomCotton\n",
      "prev record found\n",
      "7\n",
      "@JohnBoozman\n",
      "prev record found\n",
      "8\n",
      "@SenFeinstein\n",
      "prev record found\n",
      "9\n",
      "@SenKamalaHarris\n",
      "prev record found\n",
      "10\n",
      "@SenBennetCO\n",
      "prev record found\n",
      "11\n",
      "@SenCoryGardner\n",
      "prev record found\n",
      "12\n",
      "@ChrisMurphyCT\n",
      "prev record found\n",
      "13\n",
      "@SenBlumenthal\n",
      "prev record found\n",
      "14\n",
      "@SenatorCarper\n",
      "prev record found\n",
      "15\n",
      "@ChrisCoons\n",
      "prev record found\n",
      "16\n",
      "@SenBillNelson\n",
      "prev record found\n",
      "17\n",
      "@marcorubio\n",
      "prev record found\n",
      "18\n",
      "@sendavidperdue\n",
      "prev record found\n",
      "19\n",
      "@SenatorIsakson\n",
      "prev record found\n",
      "20\n",
      "@brianschatz\n",
      "prev record found\n",
      "21\n",
      "@maziehirono\n",
      "prev record found\n",
      "22\n",
      "@MikeCrapo\n",
      "prev record found\n",
      "23\n",
      "@SenatorRisch\n",
      "prev record found\n",
      "24\n",
      "@SenDuckworth\n",
      "prev record found\n",
      "25\n",
      "@SenatorDurbin\n",
      "prev record found\n",
      "26\n",
      "@SenDonnelly\n",
      "prev record found\n",
      "27\n",
      "@SenToddYoung\n",
      "prev record found\n",
      "28\n",
      "@ChuckGrassley\n",
      "prev record found\n",
      "29\n",
      "@joniernst\n",
      "prev record found\n",
      "30\n",
      "@SenPatRoberts\n",
      "prev record found\n",
      "31\n",
      "@JerryMoran\n",
      "prev record found\n",
      "32\n",
      "@SenateMajLdr\n",
      "prev record found\n",
      "33\n",
      "@RandPaul\n",
      "prev record found\n",
      "34\n",
      "@BillCassidy\n",
      "prev record found\n",
      "35\n",
      "@JohnKennedyLA\n",
      "prev record found\n",
      "36\n",
      "@SenAngusKing\n",
      "prev record found\n",
      "37\n",
      "@SenatorCollins\n",
      "prev record found\n",
      "38\n",
      "@ChrisVanHollen\n",
      "prev record found\n",
      "39\n",
      "@SenatorCardin\n",
      "prev record found\n",
      "40\n",
      "@senmarkey\n",
      "prev record found\n",
      "41\n",
      "@SenWarren\n",
      "prev record found\n",
      "42\n",
      "@SenGaryPeters\n",
      "prev record found\n",
      "43\n",
      "@SenStabenow\n",
      "prev record found\n",
      "44\n",
      "@amyklobuchar\n",
      "prev record found\n",
      "45\n",
      "@SenFranken\n",
      "prev record found\n",
      "46\n",
      "@SenThadCochran\n",
      "prev record found\n",
      "47\n",
      "@SenatorWicker\n",
      "prev record found\n",
      "48\n",
      "@clairecmc\n",
      "prev record found\n",
      "49\n",
      "@RoyBlunt\n",
      "prev record found\n",
      "50\n",
      "@SteveDaines\n",
      "prev record found\n",
      "51\n",
      "@SenatorTester\n",
      "prev record found\n",
      "52\n",
      "@SenatorFischer\n",
      "prev record found\n",
      "53\n",
      "@SenSasse\n",
      "prev record found\n",
      "54\n",
      "@CatherineForNV\n",
      "prev record found\n",
      "55\n",
      "@SenDeanHeller\n",
      "prev record found\n",
      "56\n",
      "@SenatorShaheen\n",
      "prev record found\n",
      "57\n",
      "@SenatorHassan\n",
      "prev record found\n",
      "58\n",
      "@CoryBooker\n",
      "prev record found\n",
      "59\n",
      "@SenatorMenendez\n",
      "prev record found\n",
      "60\n",
      "@MartinHeinrich\n",
      "prev record found\n",
      "61\n",
      "@SenatorTomUdall\n",
      "prev record found\n",
      "62\n",
      "@SenSchumer\n",
      "prev record found\n",
      "63\n",
      "@SenGillibrand\n",
      "prev record found\n",
      "64\n",
      "@SenatorBurr\n",
      "prev record found\n",
      "65\n",
      "@SenThomTillis\n",
      "prev record found\n",
      "66\n",
      "@SenatorHeitkamp\n",
      "prev record found\n",
      "67\n",
      "@SenJohnHoeven\n",
      "prev record found\n",
      "68\n",
      "@SenSherrodBrown\n",
      "prev record found\n",
      "69\n",
      "@senrobportman\n",
      "prev record found\n",
      "70\n",
      "@JimInhofe\n",
      "prev record found\n",
      "71\n",
      "@SenatorLankford\n",
      "prev record found\n",
      "72\n",
      "@RonWyden\n",
      "prev record found\n",
      "73\n",
      "@SenJeffMerkley\n",
      "prev record found\n",
      "74\n",
      "@SenBobCasey\n",
      "prev record found\n",
      "75\n",
      "@SenToomey\n",
      "prev record found\n",
      "76\n",
      "@SenJackReed\n",
      "prev record found\n",
      "77\n",
      "@SenWhitehouse\n",
      "prev record found\n",
      "78\n",
      "@LindseyGrahamSC\n",
      "prev record found\n",
      "79\n",
      "@SenatorTimScott\n",
      "prev record found\n",
      "80\n",
      "@SenatorRounds\n",
      "prev record found\n",
      "81\n",
      "@SenJohnThune\n",
      "prev record found\n",
      "82\n",
      "@SenAlexander\n",
      "prev record found\n",
      "83\n",
      "@SenBobCorker\n",
      "prev record found\n",
      "84\n",
      "@JohnCornyn\n",
      "prev record found\n",
      "85\n",
      "@SenTedCruz\n",
      "prev record found\n",
      "86\n",
      "@SenOrrinHatch\n",
      "prev record found\n",
      "87\n",
      "@SenMikeLee\n",
      "prev record found\n",
      "88\n",
      "@SenatorLeahy\n",
      "prev record found\n",
      "89\n",
      "@SenSanders\n",
      "prev record found\n",
      "90\n",
      "@timkaine\n",
      "prev record found\n",
      "91\n",
      "@MarkWarner\n",
      "prev record found\n",
      "92\n",
      "@PattyMurray\n",
      "prev record found\n",
      "93\n",
      "@SenatorCantwell\n",
      "prev record found\n",
      "94\n",
      "@SenCapito\n",
      "prev record found\n",
      "95\n",
      "@Sen_JoeManchin\n",
      "prev record found\n",
      "96\n",
      "@SenatorBaldwin\n",
      "prev record found\n",
      "97\n",
      "@SenRonJohnson\n",
      "prev record found\n",
      "98\n",
      "@SenatorEnzi\n",
      "prev record found\n",
      "99\n",
      "@SenJohnBarrasso\n",
      "prev record found\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "limit=10; #how many times to ask Twitter to send the next batch of 200 recent Tweets.\n",
    "#handle=\"@realDonaldTrump\" #uncomment if only looking for a single handle, and replace handle shown here\n",
    "#handle='@Lin_Manuel'\n",
    "for x in range(0,100): #comment out if only looking at single handle\n",
    "#for x in range(0,1): #uncomment for single handle\n",
    "    y=x\n",
    "    handle=senators.loc[x,'Handle'] #comment out for single handle case\n",
    "    try:\n",
    "        User_tweets=pd.read_csv('User_tweets_%s.csv'%(handle))\n",
    "        print(x)\n",
    "        print(handle)\n",
    "        print('prev record found')\n",
    "    except:\n",
    "        print(x)\n",
    "        print(handle)\n",
    "        User_tweets=TweetMining.mine(handle,limit,True)\n",
    "        print('new record created')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to do some pre-processing:\n",
    "\n",
    "First, choose dimension of word vectors and create look up table for that dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "dimension=25;\n",
    "%time GloVe=GloVe_table(dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a sentiment look up table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=50000\n",
    "try:\n",
    "    LUT_sentiment_words=pd.read_csv('LUT_sentiment_words_%s.csv'%(n))\n",
    "    LUT_sentiment_words.set_index('words',inplace=True)\n",
    "except:\n",
    "    LUT_sentiment_words=Sentiment_LUT.LUT(n)\n",
    "    LUT_sentiment_words.to_csv('LUT_sentiment_words_%s.csv'%(n),index=False)\n",
    "    LUT_sentiment_words.set_index('words',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go through the collection of tweets and find sentiment and convert to word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@realDonaldTrump\n",
      "sentiment thresh:\n",
      "Wall time: 21.7 s\n",
      "vectorize\n",
      "Wall time: 4.44 s\n"
     ]
    }
   ],
   "source": [
    "#for name in range(0,len(senators)): #comment for single handle\n",
    "for name in range(0,1): #uncomment for single handle\n",
    "    #handle=senators.loc[name,\"Handle\"] #comment for single handle\n",
    "    handle=\"@realDonaldTrump\"; #uncomment for single handle (optional)\n",
    "    print(handle)\n",
    "    #dimension=25;\n",
    "    sentiment=.35\n",
    "    try:\n",
    "        User_tweets=pd.read_csv('User_tweets_%s_sentiment_%s_vector_%s.csv'%(handle,sentiment,dimension))\n",
    "        User_tweets.fillna(0,inplace=True)\n",
    "    except:\n",
    "        try:\n",
    "            User_tweets=pd.read_csv('User_tweets_%s.csv'%(handle))\n",
    "            User_tweets.dropna(inplace=True)\n",
    "            User_tweets.reset_index(inplace=True)\n",
    "            del User_tweets['index']\n",
    "            print('sentiment thresh:')\n",
    "            %time User_tweets['sentiment words']=User_tweets.loc[:,'tweets'].apply(lambda tweet: sent_words(tweet,LUT_sentiment_words,sentiment))\n",
    "            #GloVe=GloVe_table(dimension) #unneeded if GloVe defined above (run time ~30 sec, so good to not have in loop)\n",
    "            for x in range(0,dimension):\n",
    "                User_tweets.loc[:,'vector_%s'%(x)]=0\n",
    "\n",
    "            #finding a vector form of each tweet\n",
    "            vec_names=User_tweets.columns[User_tweets.columns.str.contains('vector')];\n",
    "            #need to rewrite because of the vectorize change\n",
    "            print('vectorize')\n",
    "            %time User_tweets=vectorize(User_tweets,dimension,GloVe)\n",
    "    #        %time User_tweets.loc[:,vec_names]=User_tweets.loc[:,'sentiment words'].apply(lambda words: vectorize(words,GloVe,dimension)).values\n",
    "            User_tweets.fillna(0,inplace=True)\n",
    "            #and save the sentiment and vectorized tweets\n",
    "            User_tweets.to_csv('User_tweets_%s_sentiment_%s_vector_%s.csv'%(handle,sentiment, dimension),index=False)\n",
    "        except:\n",
    "            print('no records for that handle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
